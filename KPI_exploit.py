from pyspark.sql import SparkSession
from pyspark.mllib.stat import Statistics
from pyspark.mllib.tree import RandomForest
from pyspark.mllib.regression import LabeledPoint
from pyspark import SparkContext, SparkConf
from pyspark.streaming import StreamingContext
#from pyspark.streaming.kafka import KafkaUtils



def loadMongoRDD(db, collection):
    '''
    Download data from mongodb and store it in RDD format
    '''

    spark = SparkSession \
        .builder \
        .master(f"local[*]") \
        .appName("myApp") \
        .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1') \
        .getOrCreate()

    dataRDD = spark.read.format("mongo") \
        .option('uri', f"mongodb://10.4.41.48/{db}.{collection}") \
        .load() \
        .rdd \
        .cache()

    return dataRDD, spark


def mean(x, var):
    suma = 0
    num = len(x)
    for i in range(0,num):
        suma = suma + x[i][var]
    mean = suma/num

    return float("{:.2f}".format(mean))


def counter(x):
    counter = 0
    num = len(x)
    for i in range(0,num):
        counter = counter + 1

    return counter


def generateKPIs():

    rdd,spark = loadMongoRDD(db='formatted', collection='nested_data')

    # kpi 1: to know the average of price asked for a flat/apartment per neighborhood + num apartaments to be rent/saled
    rdd1 = rdd.map(lambda x: (x['Neighborhood'], mean(x['Info Idealista'], 'price'), counter(x['Info Idealista'])))
    #rdd1.foreach(lambda r: print(r))

    # kpi2: correlación entre monthly price and RFD (family income index)
    rdd2 = rdd.map(lambda x: (x['Monthly Price (€/month)'], x['RFD most recent']))
    print(Statistics.corr(rdd2, method="pearson")) #corr of 0.98

    # kpi3: modelling (emma) → predecir precio apartamento de idealista con regresión
    rdd_data,spark = loadMongoRDD(db='formatted', collection='data')



    labelRDD = rdd_data.map(lambda x: LabeledPoint(x[15], [x[2], x[12], x[0], x[19], x[20]])) # creating LabeledPoint for each row in RDD
    (trainingData, testData) = labelRDD.randomSplit([0.7, 0.3], seed=42) # train-test split

    # Train a RandomForest model.
    model = RandomForest.trainRegressor(trainingData, categoricalFeaturesInfo={},
                                        numTrees=5, maxDepth=7, maxBins=300, seed=42)
    # Evaluate model on test instances and compute test error
    predictions = model.predict(testData.map(lambda x: x.features))
    labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)
    testMSE = labelsAndPredictions.map(lambda lp: (lp[0] - lp[1]) * (lp[0] - lp[1])).sum() / float(testData.count())
    print('Test Mean Squared Error = ' + str(testMSE))


